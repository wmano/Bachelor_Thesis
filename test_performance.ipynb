{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee54563-dc0a-4564-8e8c-50d0459515f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "from PIL import Image\n",
    "import os\n",
    "import urllib.request\n",
    "import module\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1e0364-90f3-4b72-9bc0-8f21407bfd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmanolis/miniconda3/envs/MyProject/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 hat 2370.4375MB frei von 16125.4375MB\n",
      "GPU 1 hat 15358.4375MB frei von 16125.4375MB\n",
      "GPU 2 hat 2260.4375MB frei von 16125.4375MB\n",
      "GPU 3 hat 2350.4375MB frei von 16125.4375MB\n",
      "os.environ[\"CUDA_VISIBLE_DEVICES\"] hat nicht geklappt\n",
      "PyTorch verwendet GPU: 1\n"
     ]
    }
   ],
   "source": [
    "def get_free_gpu_idx():\n",
    "    maximum = 0\n",
    "    id_graka = None\n",
    "    for i in range(4):\n",
    "        print(f\"GPU {i} hat {torch.cuda.mem_get_info(device=i)[0]/(1024**2)}MB frei von {torch.cuda.mem_get_info(device=i)[1]/(1024**2)}MB\")\n",
    "        if maximum < torch.cuda.mem_get_info(device=i)[0]:\n",
    "            maximum = torch.cuda.mem_get_info(device=i)[0]\n",
    "            id_graka = i\n",
    "    return id_graka\n",
    "\n",
    "gpu_idx = get_free_gpu_idx()\n",
    "num_workers = 2\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_idx)\n",
    "if torch.cuda.current_device() != gpu_idx:\n",
    "    print('os.environ[\"CUDA_VISIBLE_DEVICES\"] hat nicht geklappt')\n",
    "    torch.cuda.set_device(gpu_idx)\n",
    "\n",
    "device = torch.cuda.current_device()\n",
    "print(\"PyTorch verwendet GPU:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9067ae51-45d8-47f8-bce4-d9054f8f9e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "von 194920\n"
     ]
    }
   ],
   "source": [
    "draws_left = 10000\n",
    "for i in range(1):\n",
    "    data_dict = np.load(f'../cifar5m_data/cifar5m_part{0}.npz')\n",
    "    if i != 5:\n",
    "        ziehung = random.randint(0, draws_left)\n",
    "        #print('ziehung', ziehung)\n",
    "    else:\n",
    "        ziehung = draws_left\n",
    "    von = random.randint(0, 1000448-60000)\n",
    "    print('von', von)\n",
    "    draws_left -= ziehung\n",
    "    if i == 0:\n",
    "        x = data_dict[\"X\"][von:von+ziehung]\n",
    "        y = data_dict[\"Y\"][von:von+ziehung]\n",
    "    else:\n",
    "        x = np.concatenate((x, data_dict[\"X\"][von:von+ziehung]))\n",
    "        y = np.concatenate((y, data_dict[\"Y\"][von:von+ziehung]))\n",
    "    del data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db91f350-e04d-45aa-8d28-bb0343a8ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.from_numpy(x).type(torch.float).transpose(-1, 1)\n",
    "test_y = torch.from_numpy(y)\n",
    "train_set = module.TTensorDataset([test_x, test_y])\n",
    "DATA_MEANS = (train_set[:][0] / 255.0).mean(axis=(0, 2, 3))\n",
    "DATA_STD = (train_set[:][0] / 255.0).std(axis=(0, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67b3d1a3-eb39-48df-a882-87642349ec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([transforms.Normalize(DATA_MEANS, DATA_STD)])\n",
    "test_set = module.TTensorDataset([test_x, test_y], transform=test_transform)\n",
    "test_loader = module.DataLoader(test_set, batch_size=128, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e829fd0-bfc3-4047-bb3c-7deed82c3402",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.environ.get(\"PATH_CHECKPOINT\", f\"../saved_models/epoch_{700}\")\n",
    "save_name = \"ResNet\"\n",
    "pretrained_filename = os.path.join(checkpoint_path, save_name + f\"_seed{1}\" + \".ckpt\")\n",
    "model = module.CIFARModule.load_from_checkpoint(pretrained_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21a15703-6fd7-42d5-89e2-8d26e54e2011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 hat 2370.4375MB frei von 16125.4375MB\n",
      "GPU 1 hat 15334.4375MB frei von 16125.4375MB\n",
      "GPU 2 hat 2260.4375MB frei von 16125.4375MB\n",
      "GPU 3 hat 2348.4375MB frei von 16125.4375MB\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "        #default_root_dir=os.path.join(checkpoint_path, save_name),  # Where to save models\n",
    "        accelerator='gpu',\n",
    "        devices=[get_free_gpu_idx()],\n",
    "        # How many epochs to train for if no patience is set\n",
    "        max_epochs=10,\n",
    "        callbacks=[\n",
    "            #ModelCheckpoint(\n",
    "                #save_weights_only=True, mode=\"max\", monitor=\"val_acc\"\n",
    "            #),  # Save the best checkpoint based on the maximum val_acc recorded. Saves only weights and not optimizer\n",
    "            LearningRateMonitor(\"epoch\")\n",
    "        ],  # Log learning rate every epoch\n",
    "        enable_progress_bar=True,\n",
    "        # logger=tb_logger,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fd317dc-e558-45ba-a779-8b3a6132ea3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|█████████████████████████████████████████████████████████████| 24/24 [00:00<00:00, 64.79it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_result = trainer.test(model, dataloaders=test_loader, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f5645a4-6170-4f1f-b0f7-a5b201c5f516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_acc': 0.7354925870895386}]\n"
     ]
    }
   ],
   "source": [
    "print(test_result) # epoche 700, Seed 4\n",
    "# [{'test_acc': 0.7354925870895386}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2a05e1-278f-44cf-8938-6de1a005b229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_acc': 0.7231531143188477}]\n"
     ]
    }
   ],
   "source": [
    "print(test_result) # epoche 500, Seed 4\n",
    "# [{'test_acc': 0.7231531143188477}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fddf8c4d-e5b4-43aa-a6c6-001909411370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_acc': 0.7008547186851501}]\n"
     ]
    }
   ],
   "source": [
    "print(test_result) # epoche 500, Seed 1\n",
    "# [{'test_acc': 0.7008547186851501}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31d3adc3-820c-4051-8c78-218ade9aaec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_acc': 0.8544046878814697}]\n"
     ]
    }
   ],
   "source": [
    "print(test_result) # CIFAR Model Seed 4\n",
    "# [{'test_acc': 0.8544046878814697}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
